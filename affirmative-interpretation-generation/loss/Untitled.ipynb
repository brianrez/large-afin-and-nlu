{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3eeb817-9067-44ce-a01e-5b98be17ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57634af-a978-4d2a-8fd4-6d1672f9c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ffcc10-d609-4358-b515-cfad760488f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = tokenizer(\"hello I am not here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049885b7-33ba-480b-b32d-659b07f29cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = tokenizer(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2b01e1-8cee-41cc-92eb-e0b2d1eabfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [21820, 27, 183, 59, 270, 1], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1343174-fed1-4803-8298-61c38dea0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [59, 1], 'attention_mask': [1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad83f310-db14-44f1-9e83-55702e72314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(word['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5a125b-6de1-4d67-aa69-270720b3aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [7142,   10,   96, 2735,    3,   10,  328,   33,   16,    7,   15, 1893,\n",
    "         179,   30,  443, 2564,  396,    3,    5,   96,    1,    0,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d269d2b-edd4-4dec-ba2e-1ddd26344019",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = [    0, 11153,  1528,   834,  3870,  2026,  6821,    10,   105,  2735,\n",
    "            3,    10,   328,     3,    22,    60,   544,   237,    16,     8,\n",
    "          443,     3,     5,     3,   153,     1,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a048bfbb-5d4f-4133-9b41-bd8a26e74eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence: \" 2010 : They are inseparable on car ride too. \"</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adee5e73-76f3-4527-b430-56f73153429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> affirmative_interpretation: “ 2010 : They ’re together even in the car. ”</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2898084-dc54-43c0-9363-4b1254f2d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence: Moreover, Russia does not want a division of Ukraine, which could lead NATO to become established within the borders of the ex-USSR, so it is more likely it is seeking to change the facts on the ground so to be able to negotiate from a position of strength.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([7142, 10, 3, 7371, 3, 6, 4623, 405, 59, 241, 3, 9, 4889, 13, 11897, 3, 6, 84, 228, 991, 17873, 12, 582, 2127, 441, 8, 15094, 13, 8, 1215, 18, 3063, 6857, 3, 6, 78, 34, 19, 72, 952, 34, 19, 3945, 12, 483, 8, 6688, 30, 8, 1591, 78, 12, 36, 3, 179, 12, 17405, 45, 3, 9, 1102, 13, 2793, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799e9b03-6b1b-4dbb-bb90-07a11bece3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {'cls_on_input': [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 48, 49, 45,  0],\n",
    " 'concept_cls': [48, 49, 45],\n",
    " 'concept_set': [3806, 3, 9, 7142, 28, 175, 6085, 3, 10, 6112, 22750, 2561, 1],\n",
    " 'copy_mention_flag': [[0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0.]],\n",
    " 'copy_pos': [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
    " 'decoder_mention_flag': [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
    " 'gen': [1],\n",
    " 'gt': 'An old plane is sitting on a runway.',\n",
    " 'gt_concepts': ['plane', 'runway', 'sit']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d787409d-de94-41f9-a244-1ae7d2a7f9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thiser from'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inst[\"concept_cls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9993b034-9bcf-41ac-a2f1-c113da58fc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generate a sentence with these concepts : plane runway sit</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inst[\"concept_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a0b5cf-c24c-40fc-9387-589458b39904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s><pad><pad>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inst[\"copy_pos\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16416419-1bc3-472d-b4c2-7e2f267ba8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./negations.pkl\", \"rb\") as F:\n",
    "    negations = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cee9de2b-0b1e-42b5-ab62-e7c591353521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indirectly',\n",
       " 'inequality',\n",
       " 'reject',\n",
       " 'fail',\n",
       " 'in the absence of',\n",
       " 'uncommon',\n",
       " 'informal',\n",
       " 'inaction',\n",
       " 'unpopular',\n",
       " 'uninhabited',\n",
       " 'unknown',\n",
       " 'impartial',\n",
       " 'inexperienced',\n",
       " 'irregular',\n",
       " 'infrequent',\n",
       " 'unfaithful',\n",
       " 'undefeated',\n",
       " 'unofficial',\n",
       " 'unlock',\n",
       " 'inadvertently',\n",
       " 'loss',\n",
       " 'unpaid',\n",
       " 'no longer',\n",
       " 'unshaven',\n",
       " 'indistinguishable',\n",
       " 'uncarved',\n",
       " 'uneducated',\n",
       " 'refused',\n",
       " 'unconscious',\n",
       " 'unrealistic',\n",
       " 'unglazed',\n",
       " 'unpaved',\n",
       " 'lack',\n",
       " 'without',\n",
       " 'instead of',\n",
       " 'inconclusive',\n",
       " 'halt',\n",
       " 'inorganic',\n",
       " \"won't\",\n",
       " 'incorrectly',\n",
       " 'invisibility',\n",
       " 'inaccurate',\n",
       " 'unlimited',\n",
       " 'dissimilar',\n",
       " 'disrespectful',\n",
       " 'none',\n",
       " 'unstable',\n",
       " 'refuse',\n",
       " 'never',\n",
       " 'few',\n",
       " 'resist',\n",
       " 'unfortunate',\n",
       " 'unnecessary',\n",
       " 'no',\n",
       " 'unconventional',\n",
       " 'rather',\n",
       " 'invalid',\n",
       " 'unclear',\n",
       " 'nonprofessional',\n",
       " 'uneven',\n",
       " 'nobody',\n",
       " 'unhappy',\n",
       " 'nonhuman',\n",
       " 'unfavorable',\n",
       " 'unassisted',\n",
       " 'absent',\n",
       " 'inhospitable',\n",
       " 'irregularly',\n",
       " 'insensitive',\n",
       " 'unaware',\n",
       " 'impossible',\n",
       " 'a lack of',\n",
       " 'inability',\n",
       " 'unauthorized',\n",
       " 'uncertainty',\n",
       " 'not',\n",
       " 'insulator',\n",
       " 'immortal',\n",
       " 'unveil',\n",
       " 'unforgettable',\n",
       " 'ineffective',\n",
       " 'incomplete',\n",
       " 'unequivocal',\n",
       " 'unproductive',\n",
       " 'uncertain',\n",
       " 'unjust',\n",
       " 'contrary',\n",
       " 'unlighted',\n",
       " 'unseen',\n",
       " 'incorrect',\n",
       " 'except',\n",
       " 'unquestionable',\n",
       " 'unsaturated',\n",
       " 'barely',\n",
       " 'insecure',\n",
       " 'not at all',\n",
       " 'unfounded',\n",
       " 'be deprived of',\n",
       " 'hardly ever',\n",
       " 'unfashionable',\n",
       " 'dissatisfaction',\n",
       " 'avoid',\n",
       " 'uncomfortable',\n",
       " 'unclean',\n",
       " 'disagreement',\n",
       " 'untouched',\n",
       " 'unleavened',\n",
       " 'unsigned',\n",
       " 'unaddressed',\n",
       " 'with the exception of',\n",
       " 'unrelated',\n",
       " 'unserviceable',\n",
       " 'asexual',\n",
       " 'uninvolved',\n",
       " 'little',\n",
       " 'unprecedented',\n",
       " 'undeveloped',\n",
       " 'untrained',\n",
       " 'unconstitutional',\n",
       " 'unconditional',\n",
       " 'unequipped',\n",
       " 'unlike',\n",
       " 'deny',\n",
       " 'unusual',\n",
       " 'unpowered',\n",
       " 'absence',\n",
       " 'unmarried',\n",
       " 'unicameral',\n",
       " 'cannot',\n",
       " 'unaffected',\n",
       " 'unprocessed',\n",
       " 'unconnected',\n",
       " 'cease',\n",
       " 'uncanny',\n",
       " 'unsupervised',\n",
       " 'oppose',\n",
       " 'involuntary',\n",
       " 'prevent',\n",
       " 'unsafe',\n",
       " 'forbid',\n",
       " 'unintentionally',\n",
       " 'uneasy',\n",
       " 'inadequate',\n",
       " 'unborn',\n",
       " 'atypical',\n",
       " 'illegitimate',\n",
       " 'neither',\n",
       " 'disorganized',\n",
       " 'unfit',\n",
       " 'unhappily',\n",
       " 'unmyelinated',\n",
       " 'displeased',\n",
       " 'indefinite',\n",
       " 'unrestricted',\n",
       " 'unwitting',\n",
       " 'undeniable',\n",
       " 'rarely',\n",
       " 'impractical',\n",
       " \"didn't\",\n",
       " 'unadjusted',\n",
       " 'disproportionate',\n",
       " 'disagreeable',\n",
       " 'impossibility',\n",
       " 'illicit',\n",
       " 'unwieldy',\n",
       " 'destructive',\n",
       " 'dishonest',\n",
       " 'hardly',\n",
       " 'unsuccessful',\n",
       " 'exclude',\n",
       " 'could not',\n",
       " 'uncoated',\n",
       " 'disapprove',\n",
       " 'unfinished',\n",
       " 'unnoticed',\n",
       " 'inconspicuous',\n",
       " 'illegal',\n",
       " 'unsure',\n",
       " 'undamaged',\n",
       " 'nothing',\n",
       " 'infidelity',\n",
       " 'unscrupulous',\n",
       " 'nonviolent',\n",
       " 'unoccupied',\n",
       " 'unpleasant',\n",
       " 'unfairly',\n",
       " 'unable',\n",
       " 'impossible to',\n",
       " 'dislike',\n",
       " 'stop',\n",
       " 'compromising',\n",
       " 'uncontested',\n",
       " 'prohibit',\n",
       " 'untreated',\n",
       " 'incredulous',\n",
       " 'harmless',\n",
       " 'unbroken',\n",
       " 'rather than',\n",
       " 'untied',\n",
       " \"wasn't\",\n",
       " 'involuntarily',\n",
       " 'unorthodox',\n",
       " 'inequitable',\n",
       " 'unreliability',\n",
       " 'immobility',\n",
       " 'illiterate',\n",
       " 'unburned',\n",
       " 'uncensored',\n",
       " 'unwilling',\n",
       " 'unloaded',\n",
       " 'could',\n",
       " 'useless',\n",
       " 'unlikely',\n",
       " 'unaccompanied',\n",
       " 'unarmed',\n",
       " 'unlucky',\n",
       " 'disadvantage',\n",
       " 'irreversible',\n",
       " 'unexpected']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df235b05-0358-4f9b-8baa-a3fa9ff6ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a484aa7-2cca-413d-bbbf-fc14a084a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(negations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e908564-832b-47f4-b55e-045eb97f9fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25509, 1],\n",
       " [25608, 1],\n",
       " [15092, 1],\n",
       " [5124, 1],\n",
       " [16, 8, 8605, 13, 1],\n",
       " [21141, 1],\n",
       " [15347, 1],\n",
       " [16, 4787, 1],\n",
       " [73, 27302, 1],\n",
       " [73, 30732, 1],\n",
       " [7752, 1],\n",
       " [30280, 1],\n",
       " [16, 22602, 26, 1],\n",
       " [22085, 1],\n",
       " [16, 30740, 1],\n",
       " [73, 10699, 107, 1329, 1],\n",
       " [3550, 89, 15, 920, 1],\n",
       " [73, 20884, 1],\n",
       " [12502, 1],\n",
       " [16, 9, 26, 3027, 295, 120, 1],\n",
       " [1453, 1],\n",
       " [73, 12760, 1],\n",
       " [150, 1200, 1],\n",
       " [1149, 7965, 29, 1],\n",
       " [16, 19694, 1744, 1273, 179, 1],\n",
       " [73, 19619, 1],\n",
       " [245, 4817, 920, 1],\n",
       " [12191, 1],\n",
       " [25429, 1],\n",
       " [31820, 1],\n",
       " [73, 23700, 1],\n",
       " [73, 24433, 1],\n",
       " [2136, 1],\n",
       " [406, 1],\n",
       " [1446, 13, 1],\n",
       " [16, 1018, 10562, 7, 757, 1],\n",
       " [3, 5019, 1],\n",
       " [16, 11127, 447, 1],\n",
       " [751, 31, 17, 1],\n",
       " [12153, 120, 1],\n",
       " [16, 3466, 11102, 1],\n",
       " [27801, 1],\n",
       " [11875, 1],\n",
       " [1028, 26714, 1],\n",
       " [31973, 1329, 1],\n",
       " [5839, 1],\n",
       " [27644, 1],\n",
       " [9460, 1],\n",
       " [470, 1],\n",
       " [360, 1],\n",
       " [8891, 1],\n",
       " [20343, 1],\n",
       " [12592, 1],\n",
       " [150, 1],\n",
       " [30903, 1],\n",
       " [1066, 1],\n",
       " [17070, 1],\n",
       " [19363, 1],\n",
       " [529, 24318, 1],\n",
       " [24616, 1],\n",
       " [12638, 1],\n",
       " [24357, 1],\n",
       " [529, 12450, 1],\n",
       " [73, 89, 9, 1967, 179, 1],\n",
       " [73, 9, 7, 15777, 1],\n",
       " [14101, 1],\n",
       " [16, 11982, 5230, 179, 1],\n",
       " [22085, 120, 1],\n",
       " [16, 22118, 1],\n",
       " [24111, 1],\n",
       " [4586, 1],\n",
       " [3, 9, 2136, 13, 1],\n",
       " [16, 2020, 1],\n",
       " [3, 22556, 1],\n",
       " [14068, 1],\n",
       " [59, 1],\n",
       " [3, 15953, 1016, 1],\n",
       " [28224, 1],\n",
       " [27080, 1],\n",
       " [19336, 1],\n",
       " [16, 8993, 1],\n",
       " [19840, 1],\n",
       " [245, 1169, 6117, 138, 1],\n",
       " [73, 27408, 1],\n",
       " [21050, 1],\n",
       " [73, 4998, 1],\n",
       " [15943, 1],\n",
       " [73, 28858, 1],\n",
       " [1149, 15, 35, 1],\n",
       " [12153, 1],\n",
       " [3578, 1],\n",
       " [73, 7771, 1575, 179, 1],\n",
       " [1149, 6010, 920, 1],\n",
       " [11289, 1],\n",
       " [16, 24875, 1],\n",
       " [59, 44, 66, 1],\n",
       " [73, 23329, 1],\n",
       " [36, 3, 30182, 13, 1],\n",
       " [3, 10942, 664, 1],\n",
       " [73, 31692, 179, 1],\n",
       " [1028, 9275, 7, 89, 4787, 1],\n",
       " [1792, 1],\n",
       " [14209, 1],\n",
       " [73, 16480, 1],\n",
       " [28155, 1],\n",
       " [3, 31729, 1],\n",
       " [73, 109, 9, 208, 4632, 1],\n",
       " [73, 15532, 1],\n",
       " [73, 9, 26, 12039, 15, 26, 1],\n",
       " [28, 8, 5763, 13, 1],\n",
       " [73, 3897, 1],\n",
       " [73, 5114, 179, 1],\n",
       " [3, 9, 25604, 1],\n",
       " [73, 77, 4571, 162, 26, 1],\n",
       " [385, 1],\n",
       " [19534, 1],\n",
       " [73, 24468, 1],\n",
       " [73, 17, 10761, 1],\n",
       " [73, 1018, 17448, 138, 1],\n",
       " [28359, 1],\n",
       " [73, 27886, 1],\n",
       " [9770, 1],\n",
       " [177, 63, 1],\n",
       " [7225, 1],\n",
       " [73, 17124, 1],\n",
       " [8605, 1],\n",
       " [73, 1635, 9889, 1],\n",
       " [15344, 9, 935, 138, 1],\n",
       " [1178, 1],\n",
       " [73, 9, 27488, 1],\n",
       " [73, 15056, 15, 26, 1],\n",
       " [73, 19386, 1],\n",
       " [18682, 1],\n",
       " [73, 75, 15159, 1],\n",
       " [73, 23313, 1],\n",
       " [10720, 15, 1],\n",
       " [16, 4571, 14016, 651, 1],\n",
       " [1709, 1],\n",
       " [26435, 1],\n",
       " [21, 9824, 1],\n",
       " [73, 77, 9174, 1427, 1],\n",
       " [73, 20905, 1],\n",
       " [22666, 1],\n",
       " [73, 7473, 1],\n",
       " [3, 9, 21888, 1],\n",
       " [3, 173, 8492, 2998, 342, 1],\n",
       " [7598, 1],\n",
       " [1028, 28006, 1],\n",
       " [73, 5616, 1],\n",
       " [73, 107, 3096, 9203, 1],\n",
       " [73, 2258, 15, 8280, 1054, 1],\n",
       " [3, 10475, 29107, 1],\n",
       " [16, 14339, 1],\n",
       " [73, 60, 20066, 15, 26, 1],\n",
       " [73, 7820, 1222, 1],\n",
       " [64, 35, 23, 179, 1],\n",
       " [8207, 1],\n",
       " [256, 22255, 138, 1],\n",
       " [737, 31, 17, 1],\n",
       " [73, 9, 26, 4998, 15, 26, 1],\n",
       " [3, 31350, 1],\n",
       " [15788, 179, 1],\n",
       " [256, 2748, 7, 11102, 1],\n",
       " [30234, 1],\n",
       " [73, 6092, 40, 26, 63, 1],\n",
       " [24439, 1],\n",
       " [4419, 106, 222, 1],\n",
       " [3, 10942, 1],\n",
       " [26684, 1],\n",
       " [17981, 1],\n",
       " [228, 59, 1],\n",
       " [73, 509, 920, 1],\n",
       " [1028, 12497, 162, 1],\n",
       " [73, 19420, 1],\n",
       " [73, 2264, 867, 26, 1],\n",
       " [16, 8056, 6174, 13281, 1],\n",
       " [6016, 1],\n",
       " [3, 20305, 1],\n",
       " [64, 265, 11438, 1],\n",
       " [1327, 1],\n",
       " [16, 31374, 1],\n",
       " [1149, 14127, 4801, 1162, 1],\n",
       " [529, 11275, 295, 1],\n",
       " [73, 12519, 1],\n",
       " [24276, 1],\n",
       " [18216, 120, 1],\n",
       " [3, 6319, 1],\n",
       " [4586, 12, 1],\n",
       " [22461, 1],\n",
       " [1190, 1],\n",
       " [3, 24581, 1],\n",
       " [73, 29365, 1],\n",
       " [19551, 1],\n",
       " [73, 19234, 1],\n",
       " [16, 17216, 83, 1162, 1],\n",
       " [25708, 1],\n",
       " [73, 5702, 2217, 1],\n",
       " [1066, 145, 1],\n",
       " [73, 17, 5973, 1],\n",
       " [2088, 31, 17, 1],\n",
       " [16, 26704, 1],\n",
       " [73, 28383, 1],\n",
       " [16, 15, 10073, 179, 1],\n",
       " [73, 19459, 2020, 1],\n",
       " [256, 10651, 485, 1],\n",
       " [3, 173, 9842, 342, 1],\n",
       " [73, 7223, 15, 26, 1],\n",
       " [73, 25486, 15, 26, 1],\n",
       " [28963, 1],\n",
       " [73, 19496, 1],\n",
       " [228, 1],\n",
       " [19930, 1],\n",
       " [9909, 1],\n",
       " [73, 10102, 1],\n",
       " [73, 8715, 1],\n",
       " [73, 18219, 63, 1],\n",
       " [18093, 1],\n",
       " [19598, 2660, 2317, 1],\n",
       " [7544, 1]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4affd017-f29d-4f73-8aa1-55dd497ad105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n"
     ]
    }
   ],
   "source": [
    "all_len = 0\n",
    "for tokens in tokenized['input_ids']:\n",
    "    all_len += len(tokens)\n",
    "print(all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8caf22e7-edd6-4086-923d-44c3138c5930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [14261, 123, 15, 7, 10, 1], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"neg cues:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c4cb8-c65d-405f-b236-e68ed1014369",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33fdf630-c1c6-467d-987f-86bb95d3c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\n",
      "</s>\n",
      "<unk>\n",
      "\n",
      "X\n",
      ".\n",
      ",\n",
      "s\n",
      "the\n",
      "a\n",
      ":\n",
      "and\n",
      "to\n",
      "of\n",
      "fill\n",
      "e\n",
      "in\n",
      "t\n",
      "-\n",
      "is\n",
      "de\n",
      "for\n",
      "’\n",
      "i\n",
      "that\n",
      "you\n",
      "d\n",
      "I\n",
      "with\n",
      "n\n",
      "on\n",
      "'\n",
      "o\n",
      "are\n",
      "it\n",
      "en\n",
      "be\n",
      "The\n",
      "as\n",
      "your\n",
      "l\n",
      "(\n",
      "or\n",
      "have\n",
      "at\n",
      "from\n",
      "an\n",
      "was\n",
      "this\n",
      "er\n",
      "la\n",
      "m\n",
      "r\n",
      "ing\n",
      "can\n",
      "!\n",
      "will\n",
      "by\n",
      "?\n",
      "not\n",
      "re\n",
      ")\n",
      "we\n",
      "y\n",
      "und\n",
      "has\n",
      "all\n",
      "die\n",
      "but\n",
      "our\n",
      "their\n",
      "A\n",
      "more\n",
      "un\n",
      "der\n",
      "c\n",
      "u\n",
      "in\n",
      "so\n",
      "they\n",
      "one\n",
      "about\n",
      "my\n",
      "ul\n",
      "which\n",
      "à\n",
      "In\n",
      "/\n",
      "he\n",
      "f\n",
      "le\n",
      "out\n",
      "also\n",
      "des\n",
      "It\n",
      "up\n",
      "\"\n",
      "time\n",
      "ă\n",
      "if\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9380ad34-07b3-4846-bed7-62daa6f146a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mf_cal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmf_cal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mention_flag \u001b[38;5;66;03m#, pretty_mf_printer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpretty_mf_printer\u001b[39m(input_ids, decoder_id, mention_flag_matrix):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print input_ids as the first column\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print decoder_id as the first row\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# print mention_flag_matrix [decoder_len, input_len] in the middle\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     input_ids_ \u001b[38;5;241m=\u001b[39m input_ids\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mf_cal'"
     ]
    }
   ],
   "source": [
    "from mf_cal import mention_flag #, pretty_mf_printer\n",
    "def pretty_mf_printer(input_ids, decoder_id, mention_flag_matrix):\n",
    "    # print input_ids as the first column\n",
    "    # print decoder_id as the first row\n",
    "    # print mention_flag_matrix [decoder_len, input_len] in the middle\n",
    "\n",
    "    input_ids_ = input_ids\n",
    "    decoder_id_ = decoder_id\n",
    "\n",
    "    mention_flag_matrix = mention_flag_matrix.clone().tolist()\n",
    "\n",
    "    dict_ = {}\n",
    "    dict_[\"input_ids\"] = input_ids_\n",
    "    for i in range(len(decoder_id_)):\n",
    "        dict_[decoder_id_[i]] = mention_flag_matrix[i]\n",
    "\n",
    "    from pandas import DataFrame as df\n",
    "    data = df(dict_)\n",
    "    print(data)\n",
    "\n",
    "    return None\n",
    "\n",
    "input_sentence = \"Hello I am disagreeable here with this thing. neg cues: unwidely, nothing, undamaged,\"\n",
    "\n",
    "output_sentence = \"<pad> Hi I am unwidely here, talking to you, and disagreeable here\"\n",
    "\n",
    "input_id = tokenizer(input_sentence, return_tensors=\"pt\")['input_ids']\n",
    "print(type(input_id))\n",
    "decoder_id = tokenizer(output_sentence, return_tensors=\"pt\")['input_ids']\n",
    "orig_cue = tokenizer(\"disagreeable\")['input_ids'][:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mentionflag = mention_flag(input_id, decoder_id, orig_cue)\n",
    "\n",
    "input_id = [f\"{id} ({tokenizer.decode([id])})\" for id in input_id[0]]\n",
    "decoder_id = [f\"{id} ({tokenizer.decode([id])})\" for id in decoder_id[0]]\n",
    "pretty_mf_printer(input_id, decoder_id, mentionflag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380a84c-3881-4a57-80fd-64779b9db395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "this_ = torch.zeros(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f631e5-56fa-41d1-8093-a170518d9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(this_)\n",
    "print(this_.shape)\n",
    "nthis_ = torch.tensor([this_.tolist()])\n",
    "print(nthis_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a047f1-6b30-4552-b2e7-e55cd9b3d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_flag_matrix = torch.zeros((1, 50, 80))\n",
    "\n",
    "print(mention_flag_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982d466-78f7-4c36-956a-80d5225c9104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
